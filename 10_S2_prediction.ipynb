{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66c097c4-023e-44a4-814f-b564f8a3cb5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(PCG64) at 0x1CE95495FC0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import os \n",
    "import geopandas as gpd \n",
    "from msmla50 import MSMLA50\n",
    "import gc\n",
    "import utils\n",
    "import torch\n",
    "import cnn_utils\n",
    "import pickle\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "random.seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.use_deterministic_algorithms(True, warn_only=True)\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "np.random.default_rng(seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b18d377-ce15-47db-9dd9-169905243dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "patch_size = 32\n",
    "stride = 10\n",
    "gt_stride = 32\n",
    "background_label = 0\n",
    "batch_size = 128\n",
    "offset_left = 'best'\n",
    "offset_top = 'best'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151177e0-e6d9-43cd-8370-639f76604471",
   "metadata": {},
   "source": [
    "# Berlin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aeaf043e-b2e0-4ce0-b6e8-e9fe20e4900e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load splited reference data\n",
    "splited_ref_data = gpd.read_file(r'ref_data\\berlin_ref_splitS2S3S4.gpkg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52d6baf5-52d7-487e-ae60-9edcd1e94d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load satellite image (10 m resolution)\n",
    "image = r'imagery\\berlin_20170519.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bff6164-4383-4722-b43b-50f8241b19a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load trained S2 CNN models for each fold\n",
    "cnn_models = [r's2_cnn_models\\berlin_S2_fold0_epoch12.pth',\n",
    "              r's2_cnn_models\\berlin_S2_fold1_epoch16.pth',\n",
    "              r's2_cnn_models\\berlin_S2_fold2_epoch22.pth',\n",
    "              r's2_cnn_models\\berlin_S2_fold3_epoch39.pth',\n",
    "              r's2_cnn_models\\berlin_S2_fold4_epoch32.pth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "909da481-1ec9-48ce-8df1-98b4f3654e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define outputs\n",
    "outputs = [r'outputs\\s2\\berlin_S2_fold0.tif',\n",
    "          r'outputs\\s2\\berlin_S2_fold1.tif',\n",
    "          r'outputs\\s2\\berlin_S2_fold2.tif',\n",
    "          r'outputs\\s2\\berlin_S2_fold3.tif',\n",
    "          r'outputs\\s2\\berlin_S2_fold4.tif']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2426490-7c31-47c8-916e-5bcb20eb3f1c",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8307bcb0-ab28-4c4f-ad14-6f3773aec5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recording results\n",
    "folds = [0, 1, 2, 3, 4]\n",
    "\n",
    "# results[fold]\n",
    "results = {\n",
    "    fold: {} for fold in folds\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0040c614-a443-4983-8e0e-b4488a017e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total patches loaded: 418465\n"
     ]
    }
   ],
   "source": [
    "feature_patches = cnn_utils.generate_feature_patches_loader(image_path = image,patch_size = patch_size,stride = stride,batch_size = batch_size,offset_left = offset_left,offset_top = offset_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c145c04-281d-4dc0-a25d-97e9e7a18d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total ground truth patches generated: 1956\n",
      "Unique Labels: [ 2  4  5  6  8  9 11 12 13 14 16 17]\n",
      "Counts: [116  34 202 317 119  69 395  81  85 361  29 148]\n",
      "Original unique label values: [ 2  4  5  6  8  9 11 12 13 14 16 17], Counts: [116  34 202 317 119  69 395  81  85 361  29 148]\n",
      "Remapped unique label values: [ 0  1  2  3  4  5  6  7  8  9 10 11], Counts: [116  34 202 317 119  69 395  81  85 361  29 148]\n",
      "Prediction started for fold 0...\n",
      " saved to s2_outputs\\berlin_S2_fold0.tif\n",
      "Fold 0 predicted and saved to s2_outputs\\berlin_S2_fold0.tif.\n",
      "Total ground truth patches generated: 1830\n",
      "Unique Labels: [ 2  4  5  6  8  9 11 12 13 14 16 17]\n",
      "Counts: [102  41 195 320 124  53 383  76  72 320  26 118]\n",
      "Original unique label values: [ 2  4  5  6  8  9 11 12 13 14 16 17], Counts: [102  41 195 320 124  53 383  76  72 320  26 118]\n",
      "Remapped unique label values: [ 0  1  2  3  4  5  6  7  8  9 10 11], Counts: [102  41 195 320 124  53 383  76  72 320  26 118]\n",
      "Prediction started for fold 1...\n",
      " saved to s2_outputs\\berlin_S2_fold1.tif\n",
      "Fold 1 predicted and saved to s2_outputs\\berlin_S2_fold1.tif.\n",
      "Total ground truth patches generated: 1910\n",
      "Unique Labels: [ 2  4  5  6  8  9 11 12 13 14 16 17]\n",
      "Counts: [117  41 193 308 121  62 390  83  73 347  33 142]\n",
      "Original unique label values: [ 2  4  5  6  8  9 11 12 13 14 16 17], Counts: [117  41 193 308 121  62 390  83  73 347  33 142]\n",
      "Remapped unique label values: [ 0  1  2  3  4  5  6  7  8  9 10 11], Counts: [117  41 193 308 121  62 390  83  73 347  33 142]\n",
      "Prediction started for fold 2...\n",
      " saved to s2_outputs\\berlin_S2_fold2.tif\n",
      "Fold 2 predicted and saved to s2_outputs\\berlin_S2_fold2.tif.\n",
      "Total ground truth patches generated: 1909\n",
      "Unique Labels: [ 2  4  5  6  8  9 11 12 13 14 16 17]\n",
      "Counts: [120  50 187 283 129  63 403  74  76 354  21 149]\n",
      "Original unique label values: [ 2  4  5  6  8  9 11 12 13 14 16 17], Counts: [120  50 187 283 129  63 403  74  76 354  21 149]\n",
      "Remapped unique label values: [ 0  1  2  3  4  5  6  7  8  9 10 11], Counts: [120  50 187 283 129  63 403  74  76 354  21 149]\n",
      "Prediction started for fold 3...\n",
      " saved to s2_outputs\\berlin_S2_fold3.tif\n",
      "Fold 3 predicted and saved to s2_outputs\\berlin_S2_fold3.tif.\n",
      "Total ground truth patches generated: 1919\n",
      "Unique Labels: [ 2  4  5  6  8  9 11 12 13 14 16 17]\n",
      "Counts: [117  46 191 328 119  53 381  78  86 346  35 139]\n",
      "Original unique label values: [ 2  4  5  6  8  9 11 12 13 14 16 17], Counts: [117  46 191 328 119  53 381  78  86 346  35 139]\n",
      "Remapped unique label values: [ 0  1  2  3  4  5  6  7  8  9 10 11], Counts: [117  46 191 328 119  53 381  78  86 346  35 139]\n",
      "Prediction started for fold 4...\n",
      " saved to s2_outputs\\berlin_S2_fold4.tif\n",
      "Fold 4 predicted and saved to s2_outputs\\berlin_S2_fold4.tif.\n"
     ]
    }
   ],
   "source": [
    "for fold in folds:\n",
    "    ## prepare training and test polygons\n",
    "    test_polygons = splited_ref_data[splited_ref_data[\"fold\"] == fold]\n",
    "    train_polygons = splited_ref_data[splited_ref_data[\"fold\"] != fold]\n",
    "\n",
    "    train_polygons_raster = fr\"berlin_train_f{fold}.tif\"\n",
    "    test_polygons_raster = fr\"berlin_test_f{fold}.tif\"\n",
    "\n",
    "    # rasterize\n",
    "    train_temp = train_polygons_raster.replace(\".tif\", \"_temp.tif\")\n",
    "    test_temp = test_polygons_raster.replace(\".tif\", \"_temp.tif\")\n",
    "    utils.rasterize_reference_polygons(train_polygons, image, train_temp)\n",
    "    utils.rasterize_reference_polygons(test_polygons, image, test_temp)\n",
    "\n",
    "    # train and test images matched to 10m image\n",
    "    train_image_matched = utils.match_rasters(train_temp, image)\n",
    "    test_image_matched = utils.match_rasters(test_temp, image)\n",
    "\n",
    "    # save\n",
    "    train_image_matched.rio.to_raster(train_polygons_raster, driver=\"GTiff\", compress=\"LZW\")\n",
    "    test_image_matched.rio.to_raster(test_polygons_raster, driver=\"GTiff\", compress=\"LZW\")\n",
    "\n",
    "    # cleaning\n",
    "    train_image_matched.close()\n",
    "    test_image_matched.close()\n",
    "    train_image_matched = None\n",
    "    test_image_matched = None\n",
    "    gc.collect()\n",
    "    if os.path.exists(train_temp):\n",
    "        os.remove(train_temp)\n",
    "    if os.path.exists(test_temp):\n",
    "        os.remove(test_temp)\n",
    "\n",
    "    ## load trained CNN model\n",
    "    cnn_model = MSMLA50(input_channels=10, depth=[16,32,48], num_classes=len(train_polygons[\"gridcode\"].unique()))\n",
    "    cnn_model = cnn_model.cuda()\n",
    "    trained_model = torch.load(cnn_models[fold])\n",
    "    cnn_model.load_state_dict(trained_model['model_state'])\n",
    "\n",
    "    ## get training patches\n",
    "    train_patches = cnn_utils.generate_labeled_patches_loader(image_path = image,reference_path = train_polygons_raster,patch_size = patch_size,stride = gt_stride,batch_size = batch_size,offset_left = offset_left,offset_top = offset_top,background_label = background_label)\n",
    "\n",
    "    ## remapping labels\n",
    "    label_mapping = cnn_utils.compute_label_mapping(train_patches)\n",
    "    train_patches = cnn_utils.label_remapping(train_patches, label_mapping)\n",
    "\n",
    "    ## normalize patches\n",
    "    mean, std = cnn_utils.get_normalization_parameters(train_patches)\n",
    "    feature_patches_norm = cnn_utils.normalize_loader(feature_patches, mean, std)\n",
    "\n",
    "    ## prediction\n",
    "    print(f\"Prediction started for fold {fold}...\")\n",
    "    cnn_model.eval()\n",
    "    all_preds = list()\n",
    "    with torch.no_grad():\n",
    "        for features in feature_patches_norm:\n",
    "            features = features.cuda()\n",
    "            \n",
    "            pred = cnn_model(features)\n",
    "            pred = pred.cpu()\n",
    "            \n",
    "            _, predicted = torch.max(pred, 1)\n",
    "            all_preds.append(predicted)\n",
    "    y_pred = torch.cat(all_preds, dim=0)\n",
    "\n",
    "    ## remapping labels back\n",
    "    inverse_mapping = {new_label: old_label for old_label, new_label in label_mapping.items()}\n",
    "    predicted_original_labels = np.array([inverse_mapping[label] for label in y_pred.numpy()])\n",
    "\n",
    "    ## generate lcz map\n",
    "    offset_left_calc, offset_top_calc = cnn_utils.calculate_optimal_offsets(image, patch_size, stride)\n",
    "    utils.lcz_map(offset_left_calc, offset_top_calc, image, predicted_original_labels, outputs[fold])\n",
    "\n",
    "    print(f\"Fold {fold} predicted and saved to {outputs[fold]}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b77a06-44fb-4cd9-acdd-d8ea1c61d608",
   "metadata": {},
   "source": [
    "## Perpixel validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8ca0031-65d1-48f2-a36f-c74a381b34e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide test polygons raster path\n",
    "test_polygons_path = ['berlin_test_f0.tif','berlin_test_f1.tif','berlin_test_f2.tif','berlin_test_f3.tif','berlin_test_f4.tif']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96902dce-7763-4ece-b75a-e0115651167e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " saved to s2_outputs\\berlin_S2_fold0_100m.tif\n",
      " saved to s2_outputs\\berlin_S2_fold1_100m.tif\n",
      " saved to s2_outputs\\berlin_S2_fold2_100m.tif\n",
      " saved to s2_outputs\\berlin_S2_fold3_100m.tif\n",
      " saved to s2_outputs\\berlin_S2_fold4_100m.tif\n"
     ]
    }
   ],
   "source": [
    "# resample lcz map to 100m\n",
    "resampled_outputs = []\n",
    "for f in outputs:\n",
    "    out = f.replace(\".tif\", \"_100m.tif\")\n",
    "    utils.resample_lcz_map(f, out)\n",
    "    resampled_outputs.append(out)\n",
    "    # if os.path.exists(f):\n",
    "    #     try:\n",
    "    #         os.remove(f)\n",
    "    #     except:\n",
    "    #         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2099b088-de84-4bb4-bf89-5bb5123805db",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics, confusion_matrices = utils.perpixel_validation(resampled_outputs, test_polygons_path, splited_ref_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "916dbc6d-72d1-434d-9f57-59e056114fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OA</th>\n",
       "      <th>wF1</th>\n",
       "      <th>wF1_Urban</th>\n",
       "      <th>wF1_Natural</th>\n",
       "      <th>F1_Class_1</th>\n",
       "      <th>F1_Class_2</th>\n",
       "      <th>F1_Class_3</th>\n",
       "      <th>F1_Class_4</th>\n",
       "      <th>F1_Class_5</th>\n",
       "      <th>F1_Class_6</th>\n",
       "      <th>...</th>\n",
       "      <th>F1_Class_8</th>\n",
       "      <th>F1_Class_9</th>\n",
       "      <th>F1_Class_10</th>\n",
       "      <th>F1_Class_11</th>\n",
       "      <th>F1_Class_12</th>\n",
       "      <th>F1_Class_13</th>\n",
       "      <th>F1_Class_14</th>\n",
       "      <th>F1_Class_15</th>\n",
       "      <th>F1_Class_16</th>\n",
       "      <th>F1_Class_17</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76.10</td>\n",
       "      <td>74.48</td>\n",
       "      <td>71.08</td>\n",
       "      <td>79.19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.31</td>\n",
       "      <td>89.60</td>\n",
       "      <td>...</td>\n",
       "      <td>79.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.47</td>\n",
       "      <td>34.65</td>\n",
       "      <td>19.47</td>\n",
       "      <td>77.77</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>99.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80.54</td>\n",
       "      <td>77.22</td>\n",
       "      <td>66.94</td>\n",
       "      <td>85.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.94</td>\n",
       "      <td>82.45</td>\n",
       "      <td>...</td>\n",
       "      <td>77.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.95</td>\n",
       "      <td>66.09</td>\n",
       "      <td>19.85</td>\n",
       "      <td>87.77</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.49</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79.05</td>\n",
       "      <td>75.96</td>\n",
       "      <td>67.93</td>\n",
       "      <td>83.96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.56</td>\n",
       "      <td>79.80</td>\n",
       "      <td>...</td>\n",
       "      <td>78.89</td>\n",
       "      <td>47.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.84</td>\n",
       "      <td>52.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>93.46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.86</td>\n",
       "      <td>98.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>85.60</td>\n",
       "      <td>83.87</td>\n",
       "      <td>87.07</td>\n",
       "      <td>82.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.96</td>\n",
       "      <td>96.80</td>\n",
       "      <td>...</td>\n",
       "      <td>69.96</td>\n",
       "      <td>87.79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.34</td>\n",
       "      <td>59.09</td>\n",
       "      <td>43.79</td>\n",
       "      <td>94.43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.94</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85.12</td>\n",
       "      <td>83.64</td>\n",
       "      <td>83.09</td>\n",
       "      <td>85.69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.99</td>\n",
       "      <td>94.65</td>\n",
       "      <td>...</td>\n",
       "      <td>82.47</td>\n",
       "      <td>78.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.10</td>\n",
       "      <td>7.69</td>\n",
       "      <td>36.43</td>\n",
       "      <td>95.84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.58</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         OA    wF1  wF1_Urban  wF1_Natural  F1_Class_1  F1_Class_2  \\\n",
       "Fold                                                                 \n",
       "0     76.10  74.48      71.08        79.19         NaN       88.23   \n",
       "1     80.54  77.22      66.94        85.02         NaN       86.18   \n",
       "2     79.05  75.96      67.93        83.96         NaN       83.30   \n",
       "3     85.60  83.87      87.07        82.78         NaN       73.66   \n",
       "4     85.12  83.64      83.09        85.69         NaN       85.80   \n",
       "\n",
       "      F1_Class_3  F1_Class_4  F1_Class_5  F1_Class_6  ...  F1_Class_8  \\\n",
       "Fold                                                  ...               \n",
       "0            NaN         0.0       59.31       89.60  ...       79.02   \n",
       "1            NaN         0.0       61.94       82.45  ...       77.45   \n",
       "2            NaN         0.0       54.56       79.80  ...       78.89   \n",
       "3            NaN         0.0       79.96       96.80  ...       69.96   \n",
       "4            NaN         0.0       76.99       94.65  ...       82.47   \n",
       "\n",
       "      F1_Class_9  F1_Class_10  F1_Class_11  F1_Class_12  F1_Class_13  \\\n",
       "Fold                                                                   \n",
       "0           0.00          NaN        94.47        34.65        19.47   \n",
       "1           0.00          NaN        96.95        66.09        19.85   \n",
       "2          47.62          NaN        97.84        52.29         0.00   \n",
       "3          87.79          NaN        95.34        59.09        43.79   \n",
       "4          78.10          NaN        94.10         7.69        36.43   \n",
       "\n",
       "      F1_Class_14  F1_Class_15  F1_Class_16  F1_Class_17  \n",
       "Fold                                                      \n",
       "0           77.77          NaN         0.00        99.81  \n",
       "1           87.77          NaN        59.49       100.00  \n",
       "2           93.46          NaN        22.86        98.06  \n",
       "3           94.43          NaN         9.94       100.00  \n",
       "4           95.84          NaN        74.58       100.00  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_perpixel = pd.DataFrame(metrics)\n",
    "df_perpixel = df_perpixel.set_index(\"Fold\")\n",
    "df_perpixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e4b0a62-f28c-4850-a29c-2603cd2ab142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OA             81.28\n",
       "wF1            79.03\n",
       "wF1_Urban      75.22\n",
       "wF1_Natural    83.33\n",
       "F1_Class_1       NaN\n",
       "F1_Class_2     83.43\n",
       "F1_Class_3       NaN\n",
       "F1_Class_4      0.00\n",
       "F1_Class_5     66.55\n",
       "F1_Class_6     88.66\n",
       "F1_Class_7       NaN\n",
       "F1_Class_8     77.56\n",
       "F1_Class_9     42.70\n",
       "F1_Class_10      NaN\n",
       "F1_Class_11    95.74\n",
       "F1_Class_12    43.96\n",
       "F1_Class_13    23.91\n",
       "F1_Class_14    89.85\n",
       "F1_Class_15      NaN\n",
       "F1_Class_16    33.37\n",
       "F1_Class_17    99.57\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_perpixel_mean = df_perpixel.mean().round(2)\n",
    "df_perpixel_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4328f55e-d283-4741-99ec-65bd43d716f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export all results to csv\n",
    "df_perpixel.to_csv(r\"results\\s2\\berlin_S2_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3001f168-fa93-4a58-9150-fee66335864b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export confusion matrices\n",
    "with open(r\"results\\s2\\berlin_S2_confusion_matrices.pkl\", \"wb\") as f:\n",
    "    pickle.dump(confusion_matrices, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535db431-7e52-4949-a112-560ad7b2c22f",
   "metadata": {},
   "source": [
    "# Hong Kong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7685591c-ba3d-4179-924d-e357d929997c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load splited reference data\n",
    "splited_ref_data = gpd.read_file(r'ref_data\\hongkong_ref_splitS2S3S4.gpkg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d85131f-74eb-4d51-b026-d44c600bda52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load satellite image (10 m resolution)\n",
    "image = r'imagery\\hongkong_20180321.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00bf5129-9b0a-421d-9156-881a0e15abb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load trained S2 CNN models for each fold\n",
    "cnn_models = [r's2_cnn_models\\hongkong_S2_fold0_epoch43.pth',\n",
    "              r's2_cnn_models\\hongkong_S2_fold1_epoch38.pth',\n",
    "              r's2_cnn_models\\hongkong_S2_fold2_epoch33.pth',\n",
    "              r's2_cnn_models\\hongkong_S2_fold3_epoch26.pth',\n",
    "              r's2_cnn_models\\hongkong_S2_fold4_epoch29.pth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb0784b4-1ad1-4dfb-9858-a2d83a2788a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define outputs\n",
    "outputs = [r'outputs\\s2\\hongkong_S2_fold0.tif',\n",
    "          r'outputs\\s2\\hongkong_S2_fold1.tif',\n",
    "          r'outputs\\s2\\hongkong_S2_fold2.tif',\n",
    "          r'outputs\\s2\\hongkong_S2_fold3.tif',\n",
    "          r'outputs\\s2\\hongkong_S2_fold4.tif']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8b7189-0f2d-4859-bb5a-9a8c22c08d35",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9169ae76-d1e6-43a0-b73c-99bd84a8828d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recording results\n",
    "folds = [0, 1, 2, 3, 4]\n",
    "\n",
    "# results[fold]\n",
    "results = {\n",
    "    fold: {} for fold in folds\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a9801a6-3ea1-4749-9a29-f38209c9c217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total patches loaded: 214720\n"
     ]
    }
   ],
   "source": [
    "feature_patches = cnn_utils.generate_feature_patches_loader(image_path = image,patch_size = patch_size,stride = stride,batch_size = batch_size,offset_left = offset_left,offset_top = offset_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "055e6dce-ef25-4795-b885-c28375a8e152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total ground truth patches generated: 706\n",
      "Unique Labels: [ 1  2  3  4  5  6  8 10 11 12 13 14 17]\n",
      "Counts: [ 45  12  27  55   8   8  10  22 122  46  56  75 220]\n",
      "Original unique label values: [ 1  2  3  4  5  6  8 10 11 12 13 14 17], Counts: [ 45  12  27  55   8   8  10  22 122  46  56  75 220]\n",
      "Remapped unique label values: [ 0  1  2  3  4  5  6  7  8  9 10 11 12], Counts: [ 45  12  27  55   8   8  10  22 122  46  56  75 220]\n",
      "Prediction started for fold 0...\n",
      " saved to s2_outputs\\hongkong_S2_fold0.tif\n",
      "Fold 0 predicted and saved to s2_outputs\\hongkong_S2_fold0.tif.\n",
      "Total ground truth patches generated: 658\n",
      "Unique Labels: [ 1  2  3  4  5  6  8 10 11 12 13 14 17]\n",
      "Counts: [ 44  15  24  45   7   8  11  18 129  40  53  65 199]\n",
      "Original unique label values: [ 1  2  3  4  5  6  8 10 11 12 13 14 17], Counts: [ 44  15  24  45   7   8  11  18 129  40  53  65 199]\n",
      "Remapped unique label values: [ 0  1  2  3  4  5  6  7  8  9 10 11 12], Counts: [ 44  15  24  45   7   8  11  18 129  40  53  65 199]\n",
      "Prediction started for fold 1...\n",
      " saved to s2_outputs\\hongkong_S2_fold1.tif\n",
      "Fold 1 predicted and saved to s2_outputs\\hongkong_S2_fold1.tif.\n",
      "Total ground truth patches generated: 690\n",
      "Unique Labels: [ 1  2  3  4  5  6  8 10 11 12 13 14 17]\n",
      "Counts: [ 48  15  25  57   7   8   5  21 142  48  49  73 192]\n",
      "Original unique label values: [ 1  2  3  4  5  6  8 10 11 12 13 14 17], Counts: [ 48  15  25  57   7   8   5  21 142  48  49  73 192]\n",
      "Remapped unique label values: [ 0  1  2  3  4  5  6  7  8  9 10 11 12], Counts: [ 48  15  25  57   7   8   5  21 142  48  49  73 192]\n",
      "Prediction started for fold 2...\n",
      " saved to s2_outputs\\hongkong_S2_fold2.tif\n",
      "Fold 2 predicted and saved to s2_outputs\\hongkong_S2_fold2.tif.\n",
      "Total ground truth patches generated: 671\n",
      "Unique Labels: [ 1  2  3  4  5  6  8 10 11 12 13 14 17]\n",
      "Counts: [ 44  15  21  54   8   9   8  19 133  46  52  73 189]\n",
      "Original unique label values: [ 1  2  3  4  5  6  8 10 11 12 13 14 17], Counts: [ 44  15  21  54   8   9   8  19 133  46  52  73 189]\n",
      "Remapped unique label values: [ 0  1  2  3  4  5  6  7  8  9 10 11 12], Counts: [ 44  15  21  54   8   9   8  19 133  46  52  73 189]\n",
      "Prediction started for fold 3...\n",
      " saved to s2_outputs\\hongkong_S2_fold3.tif\n",
      "Fold 3 predicted and saved to s2_outputs\\hongkong_S2_fold3.tif.\n",
      "Total ground truth patches generated: 695\n",
      "Unique Labels: [ 1  2  3  4  5  6  8 10 11 12 13 14 17]\n",
      "Counts: [ 47  15  23  53   6   7  10  20 130  40  54  74 216]\n",
      "Original unique label values: [ 1  2  3  4  5  6  8 10 11 12 13 14 17], Counts: [ 47  15  23  53   6   7  10  20 130  40  54  74 216]\n",
      "Remapped unique label values: [ 0  1  2  3  4  5  6  7  8  9 10 11 12], Counts: [ 47  15  23  53   6   7  10  20 130  40  54  74 216]\n",
      "Prediction started for fold 4...\n",
      " saved to s2_outputs\\hongkong_S2_fold4.tif\n",
      "Fold 4 predicted and saved to s2_outputs\\hongkong_S2_fold4.tif.\n"
     ]
    }
   ],
   "source": [
    "for fold in folds:\n",
    "    ## prepare training and test polygons\n",
    "    test_polygons = splited_ref_data[splited_ref_data[\"fold\"] == fold]\n",
    "    train_polygons = splited_ref_data[splited_ref_data[\"fold\"] != fold]\n",
    "\n",
    "    train_polygons_raster = fr\"hongkong_train_f{fold}.tif\"\n",
    "    test_polygons_raster = fr\"hongkong_test_f{fold}.tif\"\n",
    "\n",
    "    # rasterize\n",
    "    train_temp = train_polygons_raster.replace(\".tif\", \"_temp.tif\")\n",
    "    test_temp = test_polygons_raster.replace(\".tif\", \"_temp.tif\")\n",
    "    utils.rasterize_reference_polygons(train_polygons, image, train_temp)\n",
    "    utils.rasterize_reference_polygons(test_polygons, image, test_temp)\n",
    "\n",
    "    # train and test images matched to 10m image\n",
    "    train_image_matched = utils.match_rasters(train_temp, image)\n",
    "    test_image_matched = utils.match_rasters(test_temp, image)\n",
    "\n",
    "    # save\n",
    "    train_image_matched.rio.to_raster(train_polygons_raster, driver=\"GTiff\", compress=\"LZW\")\n",
    "    test_image_matched.rio.to_raster(test_polygons_raster, driver=\"GTiff\", compress=\"LZW\")\n",
    "\n",
    "    # cleaning\n",
    "    train_image_matched.close()\n",
    "    test_image_matched.close()\n",
    "    train_image_matched = None\n",
    "    test_image_matched = None\n",
    "    gc.collect()\n",
    "    if os.path.exists(train_temp):\n",
    "        os.remove(train_temp)\n",
    "    if os.path.exists(test_temp):\n",
    "        os.remove(test_temp)\n",
    "\n",
    "    ## load trained CNN model\n",
    "    cnn_model = MSMLA50(input_channels=10, depth=[16,32,48], num_classes=len(train_polygons[\"gridcode\"].unique()))\n",
    "    cnn_model = cnn_model.cuda()\n",
    "    trained_model = torch.load(cnn_models[fold])\n",
    "    cnn_model.load_state_dict(trained_model['model_state'])\n",
    "\n",
    "    ## get training patches\n",
    "    train_patches = cnn_utils.generate_labeled_patches_loader(image_path = image,reference_path = train_polygons_raster,patch_size = patch_size,stride = gt_stride,batch_size = batch_size,offset_left = offset_left,offset_top = offset_top,background_label = background_label)\n",
    "\n",
    "    ## remapping labels\n",
    "    label_mapping = cnn_utils.compute_label_mapping(train_patches)\n",
    "    train_patches = cnn_utils.label_remapping(train_patches, label_mapping)\n",
    "\n",
    "    ## normalize patches\n",
    "    mean, std = cnn_utils.get_normalization_parameters(train_patches)\n",
    "    feature_patches_norm = cnn_utils.normalize_loader(feature_patches, mean, std)\n",
    "\n",
    "    ## prediction\n",
    "    print(f\"Prediction started for fold {fold}...\")\n",
    "    cnn_model.eval()\n",
    "    all_preds = list()\n",
    "    with torch.no_grad():\n",
    "        for features in feature_patches_norm:\n",
    "            features = features.cuda()\n",
    "            \n",
    "            pred = cnn_model(features)\n",
    "            pred = pred.cpu()\n",
    "            \n",
    "            _, predicted = torch.max(pred, 1)\n",
    "            all_preds.append(predicted)\n",
    "    y_pred = torch.cat(all_preds, dim=0)\n",
    "\n",
    "    ## remapping labels back\n",
    "    inverse_mapping = {new_label: old_label for old_label, new_label in label_mapping.items()}\n",
    "    predicted_original_labels = np.array([inverse_mapping[label] for label in y_pred.numpy()])\n",
    "\n",
    "    ## generate lcz map\n",
    "    offset_left_calc, offset_top_calc = cnn_utils.calculate_optimal_offsets(image, patch_size, stride)\n",
    "    utils.lcz_map(offset_left_calc, offset_top_calc, image, predicted_original_labels, outputs[fold])\n",
    "\n",
    "    print(f\"Fold {fold} predicted and saved to {outputs[fold]}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2f3cee-7ed0-4118-8bc6-e096dbdc00e3",
   "metadata": {},
   "source": [
    "## Perpixel validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6748b63-f565-4824-88a2-f3245233fbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide test polygons raster path\n",
    "test_polygons_path = ['hongkong_test_f0.tif','hongkong_test_f1.tif','hongkong_test_f2.tif','hongkong_test_f3.tif','hongkong_test_f4.tif']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d433a2e-43a1-47c1-9c05-0dc9b896c54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " saved to s2_outputs\\hongkong_S2_fold0_100m.tif\n",
      " saved to s2_outputs\\hongkong_S2_fold1_100m.tif\n",
      " saved to s2_outputs\\hongkong_S2_fold2_100m.tif\n",
      " saved to s2_outputs\\hongkong_S2_fold3_100m.tif\n",
      " saved to s2_outputs\\hongkong_S2_fold4_100m.tif\n"
     ]
    }
   ],
   "source": [
    "# resample lcz map to 100m\n",
    "resampled_outputs = []\n",
    "for f in outputs:\n",
    "    out = f.replace(\".tif\", \"_100m.tif\")\n",
    "    utils.resample_lcz_map(f, out)\n",
    "    resampled_outputs.append(out)\n",
    "    # if os.path.exists(f):\n",
    "    #     try:\n",
    "    #         os.remove(f)\n",
    "    #     except:\n",
    "    #         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77505dde-fdaf-47cb-a58b-52e0948b5206",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics, confusion_matrices = utils.perpixel_validation(resampled_outputs, test_polygons_path, splited_ref_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0a75669-91a0-4009-a1ce-52b5f55f8754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OA</th>\n",
       "      <th>wF1</th>\n",
       "      <th>wF1_Urban</th>\n",
       "      <th>wF1_Natural</th>\n",
       "      <th>F1_Class_1</th>\n",
       "      <th>F1_Class_2</th>\n",
       "      <th>F1_Class_3</th>\n",
       "      <th>F1_Class_4</th>\n",
       "      <th>F1_Class_5</th>\n",
       "      <th>F1_Class_6</th>\n",
       "      <th>...</th>\n",
       "      <th>F1_Class_8</th>\n",
       "      <th>F1_Class_9</th>\n",
       "      <th>F1_Class_10</th>\n",
       "      <th>F1_Class_11</th>\n",
       "      <th>F1_Class_12</th>\n",
       "      <th>F1_Class_13</th>\n",
       "      <th>F1_Class_14</th>\n",
       "      <th>F1_Class_15</th>\n",
       "      <th>F1_Class_16</th>\n",
       "      <th>F1_Class_17</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73.27</td>\n",
       "      <td>70.59</td>\n",
       "      <td>45.02</td>\n",
       "      <td>81.12</td>\n",
       "      <td>47.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>59.26</td>\n",
       "      <td>64.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>37.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.00</td>\n",
       "      <td>93.05</td>\n",
       "      <td>19.78</td>\n",
       "      <td>46.98</td>\n",
       "      <td>60.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72.79</td>\n",
       "      <td>69.34</td>\n",
       "      <td>70.80</td>\n",
       "      <td>69.32</td>\n",
       "      <td>76.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>89.71</td>\n",
       "      <td>88.42</td>\n",
       "      <td>46.15</td>\n",
       "      <td>33.33</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.23</td>\n",
       "      <td>89.19</td>\n",
       "      <td>51.16</td>\n",
       "      <td>48.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71.46</td>\n",
       "      <td>69.07</td>\n",
       "      <td>49.81</td>\n",
       "      <td>76.68</td>\n",
       "      <td>75.31</td>\n",
       "      <td>37.50</td>\n",
       "      <td>53.66</td>\n",
       "      <td>67.65</td>\n",
       "      <td>8.33</td>\n",
       "      <td>16.33</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.57</td>\n",
       "      <td>90.48</td>\n",
       "      <td>26.23</td>\n",
       "      <td>10.99</td>\n",
       "      <td>64.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70.73</td>\n",
       "      <td>69.31</td>\n",
       "      <td>56.05</td>\n",
       "      <td>77.93</td>\n",
       "      <td>51.80</td>\n",
       "      <td>27.85</td>\n",
       "      <td>67.52</td>\n",
       "      <td>73.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>8.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>96.46</td>\n",
       "      <td>55.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>74.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77.12</td>\n",
       "      <td>74.02</td>\n",
       "      <td>61.38</td>\n",
       "      <td>80.29</td>\n",
       "      <td>82.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>73.51</td>\n",
       "      <td>74.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>29.63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85.71</td>\n",
       "      <td>91.79</td>\n",
       "      <td>34.69</td>\n",
       "      <td>67.89</td>\n",
       "      <td>56.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         OA    wF1  wF1_Urban  wF1_Natural  F1_Class_1  F1_Class_2  \\\n",
       "Fold                                                                 \n",
       "0     73.27  70.59      45.02        81.12       47.35        0.00   \n",
       "1     72.79  69.34      70.80        69.32       76.88        0.00   \n",
       "2     71.46  69.07      49.81        76.68       75.31       37.50   \n",
       "3     70.73  69.31      56.05        77.93       51.80       27.85   \n",
       "4     77.12  74.02      61.38        80.29       82.17        0.00   \n",
       "\n",
       "      F1_Class_3  F1_Class_4  F1_Class_5  F1_Class_6  ...  F1_Class_8  \\\n",
       "Fold                                                  ...               \n",
       "0          59.26       64.29        0.00        0.00  ...       37.50   \n",
       "1          89.71       88.42       46.15       33.33  ...        0.00   \n",
       "2          53.66       67.65        8.33       16.33  ...        0.00   \n",
       "3          67.52       73.65        0.00        0.00  ...        8.70   \n",
       "4          73.51       74.05        0.00        0.00  ...       29.63   \n",
       "\n",
       "      F1_Class_9  F1_Class_10  F1_Class_11  F1_Class_12  F1_Class_13  \\\n",
       "Fold                                                                   \n",
       "0            NaN        74.00        93.05        19.78        46.98   \n",
       "1            NaN        30.23        89.19        51.16        48.85   \n",
       "2            NaN        59.57        90.48        26.23        10.99   \n",
       "3            NaN         0.00        96.46        55.24         0.00   \n",
       "4            NaN        85.71        91.79        34.69        67.89   \n",
       "\n",
       "      F1_Class_14  F1_Class_15  F1_Class_16  F1_Class_17  \n",
       "Fold                                                      \n",
       "0           60.25          NaN          NaN        99.44  \n",
       "1            0.00          NaN          NaN        98.43  \n",
       "2           64.62          NaN          NaN        99.40  \n",
       "3           74.70          NaN          NaN        87.09  \n",
       "4           56.80          NaN          NaN        99.87  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_perpixel = pd.DataFrame(metrics)\n",
    "df_perpixel = df_perpixel.set_index(\"Fold\")\n",
    "df_perpixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3ef7f1c-1bf5-46d1-ad9b-fb41fc39f412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OA             73.07\n",
       "wF1            70.47\n",
       "wF1_Urban      56.61\n",
       "wF1_Natural    77.07\n",
       "F1_Class_1     66.70\n",
       "F1_Class_2     13.07\n",
       "F1_Class_3     68.73\n",
       "F1_Class_4     73.61\n",
       "F1_Class_5     10.90\n",
       "F1_Class_6      9.93\n",
       "F1_Class_7       NaN\n",
       "F1_Class_8     15.17\n",
       "F1_Class_9       NaN\n",
       "F1_Class_10    49.90\n",
       "F1_Class_11    92.19\n",
       "F1_Class_12    37.42\n",
       "F1_Class_13    34.94\n",
       "F1_Class_14    51.27\n",
       "F1_Class_15      NaN\n",
       "F1_Class_16      NaN\n",
       "F1_Class_17    96.85\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_perpixel_mean = df_perpixel.mean().round(2)\n",
    "df_perpixel_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "676ee4b5-f22e-4319-ab48-7de110b1352c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export all results to csv\n",
    "df_perpixel.to_csv(r\"results\\s2\\hongkong_S2_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f87999e7-6037-45d3-9a36-f24481a4151f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export confusion matrices\n",
    "with open(r\"results\\s2\\hongkong_S2_confusion_matrices.pkl\", \"wb\") as f:\n",
    "    pickle.dump(confusion_matrices, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aaa07b8-8f4d-4ee7-9546-288e903d7297",
   "metadata": {},
   "source": [
    "# Paris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "393fdb5b-4e92-4fed-a9d2-fa09c605dc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load splited reference data\n",
    "splited_ref_data = gpd.read_file(r'ref_data\\paris_ref_splitS2S3S4.gpkg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0e71729-f3ba-493e-8411-a7c811fbcba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load satellite image (10 m resolution)\n",
    "image = r'imagery\\paris_20170526.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a47e865f-36c3-433f-b67b-6e5ffd60abd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load trained S2 CNN models for each fold\n",
    "cnn_models = [r's2_cnn_models\\paris_S2_fold0_epoch64.pth',\n",
    "              r's2_cnn_models\\paris_S2_fold1_epoch88.pth',\n",
    "              r's2_cnn_models\\paris_S2_fold2_epoch75.pth',\n",
    "              r's2_cnn_models\\paris_S2_fold3_epoch76.pth',\n",
    "              r's2_cnn_models\\paris_S2_fold4_epoch88.pth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec16f539-8d75-4401-a4b5-9dd8777e00f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define outputs\n",
    "outputs = [r'outputs\\s2\\paris_S2_fold0.tif',\n",
    "          r'outputs\\s2\\paris_S2_fold1.tif',\n",
    "          r'outputs\\s2\\paris_S2_fold2.tif',\n",
    "          r'outputs\\s2\\paris_S2_fold3.tif',\n",
    "          r'outputs\\s2\\paris_S2_fold4.tif']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818f22d1-b378-4e8d-8139-f191492417c2",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b04175ef-25eb-421c-92b9-ae3c47d5e865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recording results\n",
    "folds = [0, 1, 2, 3, 4]\n",
    "\n",
    "# results[fold]\n",
    "results = {\n",
    "    fold: {} for fold in folds\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d79e67a-b9a1-4453-8f12-229f8c1324a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total patches loaded: 976752\n"
     ]
    }
   ],
   "source": [
    "feature_patches = cnn_utils.generate_feature_patches_loader(image_path = image,patch_size = patch_size,stride = stride,batch_size = batch_size,offset_left = offset_left,offset_top = offset_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc8b6901-e7f6-43ee-95bd-0c0e0acf3bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total ground truth patches generated: 1565\n",
      "Unique Labels: [ 1  2  4  5  6  8  9 11 12 14 15 17]\n",
      "Counts: [  4 240  27  31 187  66   2 357  31 583  17  20]\n",
      "Original unique label values: [ 1  2  4  5  6  8  9 11 12 14 15 17], Counts: [  4 240  27  31 187  66   2 357  31 583  17  20]\n",
      "Remapped unique label values: [ 0  1  2  3  4  5  6  7  8  9 10 11], Counts: [  4 240  27  31 187  66   2 357  31 583  17  20]\n",
      "Prediction started for fold 0...\n",
      " saved to s2_outputs\\paris_S2_fold0.tif\n",
      "Fold 0 predicted and saved to s2_outputs\\paris_S2_fold0.tif.\n",
      "Total ground truth patches generated: 1391\n",
      "Unique Labels: [ 1  2  4  5  6  8  9 11 12 14 15 17]\n",
      "Counts: [  2  73  27  35 181  66   3 345  32 593  17  17]\n",
      "Original unique label values: [ 1  2  4  5  6  8  9 11 12 14 15 17], Counts: [  2  73  27  35 181  66   3 345  32 593  17  17]\n",
      "Remapped unique label values: [ 0  1  2  3  4  5  6  7  8  9 10 11], Counts: [  2  73  27  35 181  66   3 345  32 593  17  17]\n",
      "Prediction started for fold 1...\n",
      " saved to s2_outputs\\paris_S2_fold1.tif\n",
      "Fold 1 predicted and saved to s2_outputs\\paris_S2_fold1.tif.\n",
      "Total ground truth patches generated: 1618\n",
      "Unique Labels: [ 1  2  4  5  6  8  9 11 12 14 15 17]\n",
      "Counts: [  6 229  30  34 186  62   5 347  35 652  13  19]\n",
      "Original unique label values: [ 1  2  4  5  6  8  9 11 12 14 15 17], Counts: [  6 229  30  34 186  62   5 347  35 652  13  19]\n",
      "Remapped unique label values: [ 0  1  2  3  4  5  6  7  8  9 10 11], Counts: [  6 229  30  34 186  62   5 347  35 652  13  19]\n",
      "Prediction started for fold 2...\n",
      " saved to s2_outputs\\paris_S2_fold2.tif\n",
      "Fold 2 predicted and saved to s2_outputs\\paris_S2_fold2.tif.\n",
      "Total ground truth patches generated: 1611\n",
      "Unique Labels: [ 1  2  4  5  6  8  9 11 12 14 15 17]\n",
      "Counts: [  6 246  29  35 184  61   5 330  36 648  14  17]\n",
      "Original unique label values: [ 1  2  4  5  6  8  9 11 12 14 15 17], Counts: [  6 246  29  35 184  61   5 330  36 648  14  17]\n",
      "Remapped unique label values: [ 0  1  2  3  4  5  6  7  8  9 10 11], Counts: [  6 246  29  35 184  61   5 330  36 648  14  17]\n",
      "Prediction started for fold 3...\n",
      " saved to s2_outputs\\paris_S2_fold3.tif\n",
      "Fold 3 predicted and saved to s2_outputs\\paris_S2_fold3.tif.\n",
      "Total ground truth patches generated: 1487\n",
      "Unique Labels: [ 1  2  4  5  6  8  9 11 12 14 15 17]\n",
      "Counts: [  6 244  27  33 182  33   5 353  34 544  15  11]\n",
      "Original unique label values: [ 1  2  4  5  6  8  9 11 12 14 15 17], Counts: [  6 244  27  33 182  33   5 353  34 544  15  11]\n",
      "Remapped unique label values: [ 0  1  2  3  4  5  6  7  8  9 10 11], Counts: [  6 244  27  33 182  33   5 353  34 544  15  11]\n",
      "Prediction started for fold 4...\n",
      " saved to s2_outputs\\paris_S2_fold4.tif\n",
      "Fold 4 predicted and saved to s2_outputs\\paris_S2_fold4.tif.\n"
     ]
    }
   ],
   "source": [
    "for fold in folds:\n",
    "    ## prepare training and test polygons\n",
    "    test_polygons = splited_ref_data[splited_ref_data[\"fold\"] == fold]\n",
    "    train_polygons = splited_ref_data[splited_ref_data[\"fold\"] != fold]\n",
    "\n",
    "    train_polygons_raster = fr\"paris_train_f{fold}.tif\"\n",
    "    test_polygons_raster = fr\"paris_test_f{fold}.tif\"\n",
    "\n",
    "    # rasterize\n",
    "    train_temp = train_polygons_raster.replace(\".tif\", \"_temp.tif\")\n",
    "    test_temp = test_polygons_raster.replace(\".tif\", \"_temp.tif\")\n",
    "    utils.rasterize_reference_polygons(train_polygons, image, train_temp)\n",
    "    utils.rasterize_reference_polygons(test_polygons, image, test_temp)\n",
    "\n",
    "    # train and test images matched to 10m image\n",
    "    train_image_matched = utils.match_rasters(train_temp, image)\n",
    "    test_image_matched = utils.match_rasters(test_temp, image)\n",
    "\n",
    "    # save\n",
    "    train_image_matched.rio.to_raster(train_polygons_raster, driver=\"GTiff\", compress=\"LZW\")\n",
    "    test_image_matched.rio.to_raster(test_polygons_raster, driver=\"GTiff\", compress=\"LZW\")\n",
    "\n",
    "    # cleaning\n",
    "    train_image_matched.close()\n",
    "    test_image_matched.close()\n",
    "    train_image_matched = None\n",
    "    test_image_matched = None\n",
    "    gc.collect()\n",
    "    if os.path.exists(train_temp):\n",
    "        os.remove(train_temp)\n",
    "    if os.path.exists(test_temp):\n",
    "        os.remove(test_temp)\n",
    "\n",
    "    ## load trained CNN model\n",
    "    cnn_model = MSMLA50(input_channels=10, depth=[16,32,48], num_classes=len(train_polygons[\"gridcode\"].unique()))\n",
    "    cnn_model = cnn_model.cuda()\n",
    "    trained_model = torch.load(cnn_models[fold])\n",
    "    cnn_model.load_state_dict(trained_model['model_state'])\n",
    "\n",
    "    ## get training patches\n",
    "    train_patches = cnn_utils.generate_labeled_patches_loader(image_path = image,reference_path = train_polygons_raster,patch_size = patch_size,stride = gt_stride,batch_size = batch_size,offset_left = offset_left,offset_top = offset_top,background_label = background_label)\n",
    "\n",
    "    ## remapping labels\n",
    "    label_mapping = cnn_utils.compute_label_mapping(train_patches)\n",
    "    train_patches = cnn_utils.label_remapping(train_patches, label_mapping)\n",
    "\n",
    "    ## normalize patches\n",
    "    mean, std = cnn_utils.get_normalization_parameters(train_patches)\n",
    "    feature_patches_norm = cnn_utils.normalize_loader(feature_patches, mean, std)\n",
    "\n",
    "    ## prediction\n",
    "    print(f\"Prediction started for fold {fold}...\")\n",
    "    cnn_model.eval()\n",
    "    all_preds = list()\n",
    "    with torch.no_grad():\n",
    "        for features in feature_patches_norm:\n",
    "            features = features.cuda()\n",
    "            \n",
    "            pred = cnn_model(features)\n",
    "            pred = pred.cpu()\n",
    "            \n",
    "            _, predicted = torch.max(pred, 1)\n",
    "            all_preds.append(predicted)\n",
    "    y_pred = torch.cat(all_preds, dim=0)\n",
    "\n",
    "    ## remapping labels back\n",
    "    inverse_mapping = {new_label: old_label for old_label, new_label in label_mapping.items()}\n",
    "    predicted_original_labels = np.array([inverse_mapping[label] for label in y_pred.numpy()])\n",
    "\n",
    "    ## generate lcz map\n",
    "    offset_left_calc, offset_top_calc = cnn_utils.calculate_optimal_offsets(image, patch_size, stride)\n",
    "    utils.lcz_map(offset_left_calc, offset_top_calc, image, predicted_original_labels, outputs[fold])\n",
    "\n",
    "    print(f\"Fold {fold} predicted and saved to {outputs[fold]}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c86ba5-d423-4e71-9abb-519e39472194",
   "metadata": {},
   "source": [
    "## Perpixel validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c474b17-bbdf-47f5-8b2f-dbf016c0148e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide test polygons raster path\n",
    "test_polygons_path = ['paris_test_f0.tif','paris_test_f1.tif','paris_test_f2.tif','paris_test_f3.tif','paris_test_f4.tif']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6632ccbc-d9f2-4b5e-bf6c-c7b9122ca482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " saved to s2_outputs\\paris_S2_fold0_100m.tif\n",
      " saved to s2_outputs\\paris_S2_fold1_100m.tif\n",
      " saved to s2_outputs\\paris_S2_fold2_100m.tif\n",
      " saved to s2_outputs\\paris_S2_fold3_100m.tif\n",
      " saved to s2_outputs\\paris_S2_fold4_100m.tif\n"
     ]
    }
   ],
   "source": [
    "# resample lcz map to 100m\n",
    "resampled_outputs = []\n",
    "for f in outputs:\n",
    "    out = f.replace(\".tif\", \"_100m.tif\")\n",
    "    utils.resample_lcz_map(f, out)\n",
    "    resampled_outputs.append(out)\n",
    "    # if os.path.exists(f):\n",
    "    #     try:\n",
    "    #         os.remove(f)\n",
    "    #     except:\n",
    "    #         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5611dfad-5812-4e31-9bc8-b0490997e5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics, confusion_matrices = utils.perpixel_validation(resampled_outputs, test_polygons_path, splited_ref_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6cb355cf-3fcf-4f8a-9076-c5675feebc2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OA</th>\n",
       "      <th>wF1</th>\n",
       "      <th>wF1_Urban</th>\n",
       "      <th>wF1_Natural</th>\n",
       "      <th>F1_Class_1</th>\n",
       "      <th>F1_Class_2</th>\n",
       "      <th>F1_Class_3</th>\n",
       "      <th>F1_Class_4</th>\n",
       "      <th>F1_Class_5</th>\n",
       "      <th>F1_Class_6</th>\n",
       "      <th>...</th>\n",
       "      <th>F1_Class_8</th>\n",
       "      <th>F1_Class_9</th>\n",
       "      <th>F1_Class_10</th>\n",
       "      <th>F1_Class_11</th>\n",
       "      <th>F1_Class_12</th>\n",
       "      <th>F1_Class_13</th>\n",
       "      <th>F1_Class_14</th>\n",
       "      <th>F1_Class_15</th>\n",
       "      <th>F1_Class_16</th>\n",
       "      <th>F1_Class_17</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88.47</td>\n",
       "      <td>87.69</td>\n",
       "      <td>75.29</td>\n",
       "      <td>93.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>87.77</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.65</td>\n",
       "      <td>40.61</td>\n",
       "      <td>91.09</td>\n",
       "      <td>...</td>\n",
       "      <td>66.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91.89</td>\n",
       "      <td>36.57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95.51</td>\n",
       "      <td>95.24</td>\n",
       "      <td>93.49</td>\n",
       "      <td>97.80</td>\n",
       "      <td>42.31</td>\n",
       "      <td>99.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.82</td>\n",
       "      <td>43.54</td>\n",
       "      <td>90.49</td>\n",
       "      <td>...</td>\n",
       "      <td>77.84</td>\n",
       "      <td>53.57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.19</td>\n",
       "      <td>85.71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.64</td>\n",
       "      <td>16.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.60</td>\n",
       "      <td>89.21</td>\n",
       "      <td>83.17</td>\n",
       "      <td>93.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89.43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.03</td>\n",
       "      <td>43.43</td>\n",
       "      <td>88.41</td>\n",
       "      <td>...</td>\n",
       "      <td>75.11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.09</td>\n",
       "      <td>61.86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.29</td>\n",
       "      <td>19.44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91.18</td>\n",
       "      <td>90.54</td>\n",
       "      <td>85.16</td>\n",
       "      <td>93.76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.52</td>\n",
       "      <td>59.41</td>\n",
       "      <td>92.05</td>\n",
       "      <td>...</td>\n",
       "      <td>71.43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.72</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>95.62</td>\n",
       "      <td>95.73</td>\n",
       "      <td>90.93</td>\n",
       "      <td>98.16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.00</td>\n",
       "      <td>58.93</td>\n",
       "      <td>98.12</td>\n",
       "      <td>...</td>\n",
       "      <td>89.17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.98</td>\n",
       "      <td>76.51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.60</td>\n",
       "      <td>53.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         OA    wF1  wF1_Urban  wF1_Natural  F1_Class_1  F1_Class_2  \\\n",
       "Fold                                                                 \n",
       "0     88.47  87.69      75.29        93.67        0.00       87.77   \n",
       "1     95.51  95.24      93.49        97.80       42.31       99.52   \n",
       "2     88.60  89.21      83.17        93.89         NaN       89.43   \n",
       "3     91.18  90.54      85.16        93.76         NaN       88.81   \n",
       "4     95.62  95.73      90.93        98.16         NaN       95.83   \n",
       "\n",
       "      F1_Class_3  F1_Class_4  F1_Class_5  F1_Class_6  ...  F1_Class_8  \\\n",
       "Fold                                                  ...               \n",
       "0            NaN       23.65       40.61       91.09  ...       66.26   \n",
       "1            NaN       60.82       43.54       90.49  ...       77.84   \n",
       "2            NaN       42.03       43.43       88.41  ...       75.11   \n",
       "3            NaN       51.52       59.41       92.05  ...       71.43   \n",
       "4            NaN       54.00       58.93       98.12  ...       89.17   \n",
       "\n",
       "      F1_Class_9  F1_Class_10  F1_Class_11  F1_Class_12  F1_Class_13  \\\n",
       "Fold                                                                   \n",
       "0           0.00          NaN        91.89        36.57          NaN   \n",
       "1          53.57          NaN        98.19        85.71          NaN   \n",
       "2            NaN          NaN        97.09        61.86          NaN   \n",
       "3            NaN          NaN        97.72         0.00          NaN   \n",
       "4            NaN          NaN        98.98        76.51          NaN   \n",
       "\n",
       "      F1_Class_14  F1_Class_15  F1_Class_16  F1_Class_17  \n",
       "Fold                                                      \n",
       "0           98.53         0.00          NaN        88.00  \n",
       "1           98.64        16.00          NaN        98.51  \n",
       "2           97.29        19.44          NaN        90.91  \n",
       "3           98.98         0.00          NaN        83.72  \n",
       "4           99.60        53.33          NaN        93.27  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_perpixel = pd.DataFrame(metrics)\n",
    "df_perpixel = df_perpixel.set_index(\"Fold\")\n",
    "df_perpixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "97f86c82-f3ad-481c-97a1-b38493869256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OA             91.88\n",
       "wF1            91.68\n",
       "wF1_Urban      85.61\n",
       "wF1_Natural    95.46\n",
       "F1_Class_1     21.16\n",
       "F1_Class_2     92.27\n",
       "F1_Class_3       NaN\n",
       "F1_Class_4     46.40\n",
       "F1_Class_5     49.18\n",
       "F1_Class_6     92.03\n",
       "F1_Class_7       NaN\n",
       "F1_Class_8     75.96\n",
       "F1_Class_9     26.78\n",
       "F1_Class_10      NaN\n",
       "F1_Class_11    96.77\n",
       "F1_Class_12    52.13\n",
       "F1_Class_13      NaN\n",
       "F1_Class_14    98.61\n",
       "F1_Class_15    17.75\n",
       "F1_Class_16      NaN\n",
       "F1_Class_17    90.88\n",
       "dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_perpixel_mean = df_perpixel.mean().round(2)\n",
    "df_perpixel_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "82045687-9d8f-42ce-89e1-36abc479bf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export all results to csv\n",
    "df_perpixel.to_csv(r\"results\\s2\\paris_S2_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1a441bdd-34e3-4637-b4b1-294112263012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export confusion matrices\n",
    "with open(r\"results\\s2\\paris_S2_confusion_matrices.pkl\", \"wb\") as f:\n",
    "    pickle.dump(confusion_matrices, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac117945-ce19-479e-a537-8ac23d13bad3",
   "metadata": {},
   "source": [
    "# Rome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84a06930-bef8-4dde-82a9-91479c63757c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load splited reference data\n",
    "splited_ref_data = gpd.read_file(r'ref_data\\rome_ref_splitS2S3S4.gpkg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6e34bf4-af47-4926-8682-e47a1e13fda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load satellite image (10 m resolution)\n",
    "image = r'imagery\\rome_20170620.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63ea0923-79e1-4797-9b23-2713508f15d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load trained S2 CNN models for each fold\n",
    "cnn_models = [r's2_cnn_models\\rome_S2_fold0_epoch17.pth',\n",
    "              r's2_cnn_models\\rome_S2_fold1_epoch10.pth',\n",
    "              r's2_cnn_models\\rome_S2_fold2_epoch90.pth',\n",
    "              r's2_cnn_models\\rome_S2_fold3_epoch76.pth',\n",
    "              r's2_cnn_models\\rome_S2_fold4_epoch20.pth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37e79b7e-e327-4862-a83e-9af6405db1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define outputs\n",
    "outputs = [r'outputs\\s2\\rome_S2_fold0.tif',\n",
    "          r'outputs\\s2\\rome_S2_fold1.tif',\n",
    "          r'outputs\\s2\\rome_S2_fold2.tif',\n",
    "          r'outputs\\s2\\rome_S2_fold3.tif',\n",
    "          r'outputs\\s2\\rome_S2_fold4.tif']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43471c1-77f4-425c-9c13-8e8e2d61c0ce",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c224534-7c3f-48e4-bf58-66280e6cc20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recording results\n",
    "folds = [0, 1, 2, 3, 4]\n",
    "\n",
    "# results[fold]\n",
    "results = {\n",
    "    fold: {} for fold in folds\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00667ce6-4ffd-4a0d-97ba-dfa6b06a48cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total patches loaded: 181196\n"
     ]
    }
   ],
   "source": [
    "feature_patches = cnn_utils.generate_feature_patches_loader(image_path = image,patch_size = patch_size,stride = stride,batch_size = batch_size,offset_left = offset_left,offset_top = offset_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "265ee2b3-24d0-4c8f-bce6-a9a543a0f9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total ground truth patches generated: 485\n",
      "Unique Labels: [ 2  3  5  6  8 10 11 12 14 17]\n",
      "Counts: [125   3 111  40  36   3  24  42  83  18]\n",
      "Original unique label values: [ 2  3  5  6  8 10 11 12 14 17], Counts: [125   3 111  40  36   3  24  42  83  18]\n",
      "Remapped unique label values: [0 1 2 3 4 5 6 7 8 9], Counts: [125   3 111  40  36   3  24  42  83  18]\n",
      "Prediction started for fold 0...\n",
      " saved to s2_outputs\\rome_S2_fold0.tif\n",
      "Fold 0 predicted and saved to s2_outputs\\rome_S2_fold0.tif.\n",
      "Total ground truth patches generated: 490\n",
      "Unique Labels: [ 2  3  5  6  8 10 11 12 14 17]\n",
      "Counts: [123   8 114  37  33   2  22  39  66  46]\n",
      "Original unique label values: [ 2  3  5  6  8 10 11 12 14 17], Counts: [123   8 114  37  33   2  22  39  66  46]\n",
      "Remapped unique label values: [0 1 2 3 4 5 6 7 8 9], Counts: [123   8 114  37  33   2  22  39  66  46]\n",
      "Prediction started for fold 1...\n",
      " saved to s2_outputs\\rome_S2_fold1.tif\n",
      "Fold 1 predicted and saved to s2_outputs\\rome_S2_fold1.tif.\n",
      "Total ground truth patches generated: 489\n",
      "Unique Labels: [ 2  3  5  6  8 10 11 12 14 17]\n",
      "Counts: [116  11 109  38  37   5  22  32  85  34]\n",
      "Original unique label values: [ 2  3  5  6  8 10 11 12 14 17], Counts: [116  11 109  38  37   5  22  32  85  34]\n",
      "Remapped unique label values: [0 1 2 3 4 5 6 7 8 9], Counts: [116  11 109  38  37   5  22  32  85  34]\n",
      "Prediction started for fold 2...\n",
      " saved to s2_outputs\\rome_S2_fold2.tif\n",
      "Fold 2 predicted and saved to s2_outputs\\rome_S2_fold2.tif.\n",
      "Total ground truth patches generated: 509\n",
      "Unique Labels: [ 2  3  5  6  8 10 11 12 14 17]\n",
      "Counts: [112  11 112  37  36   5  27  46  74  49]\n",
      "Original unique label values: [ 2  3  5  6  8 10 11 12 14 17], Counts: [112  11 112  37  36   5  27  46  74  49]\n",
      "Remapped unique label values: [0 1 2 3 4 5 6 7 8 9], Counts: [112  11 112  37  36   5  27  46  74  49]\n",
      "Prediction started for fold 3...\n",
      " saved to s2_outputs\\rome_S2_fold3.tif\n",
      "Fold 3 predicted and saved to s2_outputs\\rome_S2_fold3.tif.\n",
      "Total ground truth patches generated: 499\n",
      "Unique Labels: [ 2  3  5  6  8 10 11 12 14 17]\n",
      "Counts: [124  11 106  40  38   5  17  49  60  49]\n",
      "Original unique label values: [ 2  3  5  6  8 10 11 12 14 17], Counts: [124  11 106  40  38   5  17  49  60  49]\n",
      "Remapped unique label values: [0 1 2 3 4 5 6 7 8 9], Counts: [124  11 106  40  38   5  17  49  60  49]\n",
      "Prediction started for fold 4...\n",
      " saved to s2_outputs\\rome_S2_fold4.tif\n",
      "Fold 4 predicted and saved to s2_outputs\\rome_S2_fold4.tif.\n"
     ]
    }
   ],
   "source": [
    "for fold in folds:\n",
    "    ## prepare training and test polygons\n",
    "    test_polygons = splited_ref_data[splited_ref_data[\"fold\"] == fold]\n",
    "    train_polygons = splited_ref_data[splited_ref_data[\"fold\"] != fold]\n",
    "\n",
    "    train_polygons_raster = fr\"rome_train_f{fold}.tif\"\n",
    "    test_polygons_raster = fr\"rome_test_f{fold}.tif\"\n",
    "\n",
    "    # rasterize\n",
    "    train_temp = train_polygons_raster.replace(\".tif\", \"_temp.tif\")\n",
    "    test_temp = test_polygons_raster.replace(\".tif\", \"_temp.tif\")\n",
    "    utils.rasterize_reference_polygons(train_polygons, image, train_temp)\n",
    "    utils.rasterize_reference_polygons(test_polygons, image, test_temp)\n",
    "\n",
    "    # train and test images matched to 10m image\n",
    "    train_image_matched = utils.match_rasters(train_temp, image)\n",
    "    test_image_matched = utils.match_rasters(test_temp, image)\n",
    "\n",
    "    # save\n",
    "    train_image_matched.rio.to_raster(train_polygons_raster, driver=\"GTiff\", compress=\"LZW\")\n",
    "    test_image_matched.rio.to_raster(test_polygons_raster, driver=\"GTiff\", compress=\"LZW\")\n",
    "\n",
    "    # cleaning\n",
    "    train_image_matched.close()\n",
    "    test_image_matched.close()\n",
    "    train_image_matched = None\n",
    "    test_image_matched = None\n",
    "    gc.collect()\n",
    "    if os.path.exists(train_temp):\n",
    "        os.remove(train_temp)\n",
    "    if os.path.exists(test_temp):\n",
    "        os.remove(test_temp)\n",
    "\n",
    "    ## load trained CNN model\n",
    "    cnn_model = MSMLA50(input_channels=10, depth=[16,32,48], num_classes=len(train_polygons[\"gridcode\"].unique()))\n",
    "    cnn_model = cnn_model.cuda()\n",
    "    trained_model = torch.load(cnn_models[fold])\n",
    "    cnn_model.load_state_dict(trained_model['model_state'])\n",
    "\n",
    "    ## get training patches\n",
    "    train_patches = cnn_utils.generate_labeled_patches_loader(image_path = image,reference_path = train_polygons_raster,patch_size = patch_size,stride = gt_stride,batch_size = batch_size,offset_left = offset_left,offset_top = offset_top,background_label = background_label)\n",
    "\n",
    "    ## remapping labels\n",
    "    label_mapping = cnn_utils.compute_label_mapping(train_patches)\n",
    "    train_patches = cnn_utils.label_remapping(train_patches, label_mapping)\n",
    "\n",
    "    ## normalize patches\n",
    "    mean, std = cnn_utils.get_normalization_parameters(train_patches)\n",
    "    feature_patches_norm = cnn_utils.normalize_loader(feature_patches, mean, std)\n",
    "\n",
    "    ## prediction\n",
    "    print(f\"Prediction started for fold {fold}...\")\n",
    "    cnn_model.eval()\n",
    "    all_preds = list()\n",
    "    with torch.no_grad():\n",
    "        for features in feature_patches_norm:\n",
    "            features = features.cuda()\n",
    "            \n",
    "            pred = cnn_model(features)\n",
    "            pred = pred.cpu()\n",
    "            \n",
    "            _, predicted = torch.max(pred, 1)\n",
    "            all_preds.append(predicted)\n",
    "    y_pred = torch.cat(all_preds, dim=0)\n",
    "\n",
    "    ## remapping labels back\n",
    "    inverse_mapping = {new_label: old_label for old_label, new_label in label_mapping.items()}\n",
    "    predicted_original_labels = np.array([inverse_mapping[label] for label in y_pred.numpy()])\n",
    "\n",
    "    ## generate lcz map\n",
    "    offset_left_calc, offset_top_calc = cnn_utils.calculate_optimal_offsets(image, patch_size, stride)\n",
    "    utils.lcz_map(offset_left_calc, offset_top_calc, image, predicted_original_labels, outputs[fold])\n",
    "\n",
    "    print(f\"Fold {fold} predicted and saved to {outputs[fold]}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f33d87-32b0-4f15-80ec-e2c8c2609b81",
   "metadata": {},
   "source": [
    "## Perpixel validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e26bac7-96f9-4a8a-9ca8-a602630f848f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide test polygons raster path\n",
    "test_polygons_path = ['rome_test_f0.tif','rome_test_f1.tif','rome_test_f2.tif','rome_test_f3.tif','rome_test_f4.tif']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00753443-9dd1-4568-82af-7db98e5922a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " saved to s2_outputs\\rome_S2_fold0_100m.tif\n",
      " saved to s2_outputs\\rome_S2_fold1_100m.tif\n",
      " saved to s2_outputs\\rome_S2_fold2_100m.tif\n",
      " saved to s2_outputs\\rome_S2_fold3_100m.tif\n",
      " saved to s2_outputs\\rome_S2_fold4_100m.tif\n"
     ]
    }
   ],
   "source": [
    "# resample lcz map to 100m\n",
    "resampled_outputs = []\n",
    "for f in outputs:\n",
    "    out = f.replace(\".tif\", \"_100m.tif\")\n",
    "    utils.resample_lcz_map(f, out)\n",
    "    resampled_outputs.append(out)\n",
    "    # if os.path.exists(f):\n",
    "    #     try:\n",
    "    #         os.remove(f)\n",
    "    #     except:\n",
    "    #         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5d153b5-08dc-4cce-be1e-2602b60202a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics, confusion_matrices = utils.perpixel_validation(resampled_outputs, test_polygons_path, splited_ref_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a475101-256d-4ecf-bdd7-1ec4238a1c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OA</th>\n",
       "      <th>wF1</th>\n",
       "      <th>wF1_Urban</th>\n",
       "      <th>wF1_Natural</th>\n",
       "      <th>F1_Class_1</th>\n",
       "      <th>F1_Class_2</th>\n",
       "      <th>F1_Class_3</th>\n",
       "      <th>F1_Class_4</th>\n",
       "      <th>F1_Class_5</th>\n",
       "      <th>F1_Class_6</th>\n",
       "      <th>...</th>\n",
       "      <th>F1_Class_8</th>\n",
       "      <th>F1_Class_9</th>\n",
       "      <th>F1_Class_10</th>\n",
       "      <th>F1_Class_11</th>\n",
       "      <th>F1_Class_12</th>\n",
       "      <th>F1_Class_13</th>\n",
       "      <th>F1_Class_14</th>\n",
       "      <th>F1_Class_15</th>\n",
       "      <th>F1_Class_16</th>\n",
       "      <th>F1_Class_17</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68.84</td>\n",
       "      <td>64.31</td>\n",
       "      <td>54.55</td>\n",
       "      <td>86.65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>55.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.48</td>\n",
       "      <td>95.12</td>\n",
       "      <td>16.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72.16</td>\n",
       "      <td>68.00</td>\n",
       "      <td>60.72</td>\n",
       "      <td>84.19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>89.74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>96.20</td>\n",
       "      <td>65.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82.65</td>\n",
       "      <td>82.88</td>\n",
       "      <td>80.22</td>\n",
       "      <td>91.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67.47</td>\n",
       "      <td>64.57</td>\n",
       "      <td>...</td>\n",
       "      <td>83.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.64</td>\n",
       "      <td>82.82</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75.72</td>\n",
       "      <td>72.58</td>\n",
       "      <td>67.20</td>\n",
       "      <td>91.38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>83.91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.83</td>\n",
       "      <td>78.63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88.14</td>\n",
       "      <td>88.44</td>\n",
       "      <td>87.09</td>\n",
       "      <td>91.28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89.56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.48</td>\n",
       "      <td>85.28</td>\n",
       "      <td>...</td>\n",
       "      <td>93.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91.17</td>\n",
       "      <td>25.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         OA    wF1  wF1_Urban  wF1_Natural  F1_Class_1  F1_Class_2  \\\n",
       "Fold                                                                 \n",
       "0     68.84  64.31      54.55        86.65         NaN       69.34   \n",
       "1     72.16  68.00      60.72        84.19         NaN       74.96   \n",
       "2     82.65  82.88      80.22        91.92         NaN       93.29   \n",
       "3     75.72  72.58      67.20        91.38         NaN       84.37   \n",
       "4     88.14  88.44      87.09        91.28         NaN       89.56   \n",
       "\n",
       "      F1_Class_3  F1_Class_4  F1_Class_5  F1_Class_6  ...  F1_Class_8  \\\n",
       "Fold                                                  ...               \n",
       "0            0.0         NaN       60.13        0.00  ...       55.93   \n",
       "1            0.0         NaN       68.43        0.00  ...       89.74   \n",
       "2            NaN         NaN       67.47       64.57  ...       83.02   \n",
       "3            NaN         NaN       62.09        0.00  ...       83.91   \n",
       "4            NaN         NaN       84.48       85.28  ...       93.06   \n",
       "\n",
       "      F1_Class_9  F1_Class_10  F1_Class_11  F1_Class_12  F1_Class_13  \\\n",
       "Fold                                                                   \n",
       "0            NaN        90.48        95.12        16.33          NaN   \n",
       "1            NaN         0.00        96.20        65.00          NaN   \n",
       "2            NaN          NaN        94.64        82.82          NaN   \n",
       "3            NaN          NaN        45.83        78.63          NaN   \n",
       "4            NaN          NaN        91.17        25.00          NaN   \n",
       "\n",
       "      F1_Class_14  F1_Class_15  F1_Class_16  F1_Class_17  \n",
       "Fold                                                      \n",
       "0           97.61          NaN          NaN        100.0  \n",
       "1           83.66          NaN          NaN        100.0  \n",
       "2           76.68          NaN          NaN        100.0  \n",
       "3           98.41          NaN          NaN          NaN  \n",
       "4           95.61          NaN          NaN          NaN  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_perpixel = pd.DataFrame(metrics)\n",
    "df_perpixel = df_perpixel.set_index(\"Fold\")\n",
    "df_perpixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b168c2dc-a75a-429c-bbcf-157844fa8830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OA              77.50\n",
       "wF1             75.24\n",
       "wF1_Urban       69.96\n",
       "wF1_Natural     89.08\n",
       "F1_Class_1        NaN\n",
       "F1_Class_2      82.30\n",
       "F1_Class_3       0.00\n",
       "F1_Class_4        NaN\n",
       "F1_Class_5      68.52\n",
       "F1_Class_6      29.97\n",
       "F1_Class_7        NaN\n",
       "F1_Class_8      81.13\n",
       "F1_Class_9        NaN\n",
       "F1_Class_10     45.24\n",
       "F1_Class_11     84.59\n",
       "F1_Class_12     53.56\n",
       "F1_Class_13       NaN\n",
       "F1_Class_14     90.39\n",
       "F1_Class_15       NaN\n",
       "F1_Class_16       NaN\n",
       "F1_Class_17    100.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_perpixel_mean = df_perpixel.mean().round(2)\n",
    "df_perpixel_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca18cc14-0f96-4f98-902d-a4267d2f933c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export all results to csv\n",
    "df_perpixel.to_csv(r\"results\\s2\\rome_S2_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "724bf9ef-db7e-4ac8-9355-bced9e8ad119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export confusion matrices\n",
    "with open(r\"results\\s2\\rome_S2_confusion_matrices.pkl\", \"wb\") as f:\n",
    "    pickle.dump(confusion_matrices, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404ba897-77f8-42ea-a097-7da793bd6b8f",
   "metadata": {},
   "source": [
    "# Sao Paulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5de211ef-08a2-4cd3-8b9b-198d21914535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load splited reference data\n",
    "splited_ref_data = gpd.read_file(r'ref_data\\saopaulo_ref_splitS2S3S4.gpkg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1c4ac0fc-7cda-4e1a-aed7-947da0a7a84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load satellite image (10 m resolution)\n",
    "image = r'imagery\\sao_paulo_20170726.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "af4ddff0-c5bd-4383-89fe-9c6bb4b9009e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_models = [r's2_cnn_models\\saopaulo_S2_fold0_epoch67.pth',\n",
    "              r's2_cnn_models\\saopaulo_S2_fold1_epoch84.pth',\n",
    "              r's2_cnn_models\\saopaulo_S2_fold2_epoch67.pth',\n",
    "              r's2_cnn_models\\saopaulo_S2_fold3_epoch78.pth',\n",
    "              r's2_cnn_models\\saopaulo_S2_fold4_epoch37.pth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "23e4ec8c-35ae-48e2-a541-7db930d7ef0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define outputs\n",
    "outputs = [r'outputs\\s2\\saopaulo_S2_fold0.tif',\n",
    "          r'outputs\\s2\\saopaulo_S2_fold1.tif',\n",
    "          r'outputs\\s2\\saopaulo_S2_fold2.tif',\n",
    "          r'outputs\\s2\\saopaulo_S2_fold3.tif',\n",
    "          r'outputs\\s2\\saopaulo_S2_fold4.tif']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed467109-20a0-4178-a725-c00018a83587",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5483649f-41bc-466c-a643-2995a36f1275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recording results\n",
    "folds = [0, 1, 2, 3, 4]\n",
    "\n",
    "# results[fold]\n",
    "results = {\n",
    "    fold: {} for fold in folds\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b0823d81-2512-4e24-a016-1ff70c424c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total patches loaded: 508599\n"
     ]
    }
   ],
   "source": [
    "feature_patches = cnn_utils.generate_feature_patches_loader(image_path = image,patch_size = patch_size,stride = stride,batch_size = batch_size,offset_left = offset_left,offset_top = offset_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "29a2677a-7164-4a37-90d9-e10dd6e16971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total ground truth patches generated: 1787\n",
      "Unique Labels: [ 1  2  3  4  5  6  8  9 10 11 12 14 15 16 17]\n",
      "Counts: [ 71  12 422  43  19 135 148  17   2 588  23  31   9  10 257]\n",
      "Original unique label values: [ 1  2  3  4  5  6  8  9 10 11 12 14 15 16 17], Counts: [ 71  12 422  43  19 135 148  17   2 588  23  31   9  10 257]\n",
      "Remapped unique label values: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14], Counts: [ 71  12 422  43  19 135 148  17   2 588  23  31   9  10 257]\n",
      "Prediction started for fold 0...\n",
      " saved to s2_outputs\\saopaulo_S2_fold0.tif\n",
      "Fold 0 predicted and saved to s2_outputs\\saopaulo_S2_fold0.tif.\n",
      "Total ground truth patches generated: 1799\n",
      "Unique Labels: [ 1  2  3  4  5  6  8  9 10 11 12 14 15 16 17]\n",
      "Counts: [ 70  11 387  39  21 140 147  30  13 587  17  32   9  12 284]\n",
      "Original unique label values: [ 1  2  3  4  5  6  8  9 10 11 12 14 15 16 17], Counts: [ 70  11 387  39  21 140 147  30  13 587  17  32   9  12 284]\n",
      "Remapped unique label values: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14], Counts: [ 70  11 387  39  21 140 147  30  13 587  17  32   9  12 284]\n",
      "Prediction started for fold 1...\n",
      " saved to s2_outputs\\saopaulo_S2_fold1.tif\n",
      "Fold 1 predicted and saved to s2_outputs\\saopaulo_S2_fold1.tif.\n",
      "Total ground truth patches generated: 1548\n",
      "Unique Labels: [ 1  2  3  4  5  6  8  9 10 11 12 14 15 16 17]\n",
      "Counts: [ 74  11 426  38  11 137 145  27  15 331  20  27  10  11 265]\n",
      "Original unique label values: [ 1  2  3  4  5  6  8  9 10 11 12 14 15 16 17], Counts: [ 74  11 426  38  11 137 145  27  15 331  20  27  10  11 265]\n",
      "Remapped unique label values: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14], Counts: [ 74  11 426  38  11 137 145  27  15 331  20  27  10  11 265]\n",
      "Prediction started for fold 2...\n",
      " saved to s2_outputs\\saopaulo_S2_fold2.tif\n",
      "Fold 2 predicted and saved to s2_outputs\\saopaulo_S2_fold2.tif.\n",
      "Total ground truth patches generated: 1815\n",
      "Unique Labels: [ 1  2  3  4  5  6  8  9 10 11 12 14 15 16 17]\n",
      "Counts: [ 77  11 434  42  20 140 155  37  15 543  22  25   9   9 276]\n",
      "Original unique label values: [ 1  2  3  4  5  6  8  9 10 11 12 14 15 16 17], Counts: [ 77  11 434  42  20 140 155  37  15 543  22  25   9   9 276]\n",
      "Remapped unique label values: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14], Counts: [ 77  11 434  42  20 140 155  37  15 543  22  25   9   9 276]\n",
      "Prediction started for fold 3...\n",
      " saved to s2_outputs\\saopaulo_S2_fold3.tif\n",
      "Fold 3 predicted and saved to s2_outputs\\saopaulo_S2_fold3.tif.\n",
      "Total ground truth patches generated: 1679\n",
      "Unique Labels: [ 1  2  3  4  5  6  8  9 10 11 12 14 15 16 17]\n",
      "Counts: [ 72  11 431  34  21 140 157  37  15 407  22  29   3  10 290]\n",
      "Original unique label values: [ 1  2  3  4  5  6  8  9 10 11 12 14 15 16 17], Counts: [ 72  11 431  34  21 140 157  37  15 407  22  29   3  10 290]\n",
      "Remapped unique label values: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14], Counts: [ 72  11 431  34  21 140 157  37  15 407  22  29   3  10 290]\n",
      "Prediction started for fold 4...\n",
      " saved to s2_outputs\\saopaulo_S2_fold4.tif\n",
      "Fold 4 predicted and saved to s2_outputs\\saopaulo_S2_fold4.tif.\n"
     ]
    }
   ],
   "source": [
    "for fold in folds:\n",
    "    ## prepare training and test polygons\n",
    "    test_polygons = splited_ref_data[splited_ref_data[\"fold\"] == fold]\n",
    "    train_polygons = splited_ref_data[splited_ref_data[\"fold\"] != fold]\n",
    "\n",
    "    train_polygons_raster = fr\"saopaulo_train_f{fold}.tif\"\n",
    "    test_polygons_raster = fr\"saopaulo_test_f{fold}.tif\"\n",
    "\n",
    "    # rasterize\n",
    "    train_temp = train_polygons_raster.replace(\".tif\", \"_temp.tif\")\n",
    "    test_temp = test_polygons_raster.replace(\".tif\", \"_temp.tif\")\n",
    "    utils.rasterize_reference_polygons(train_polygons, image, train_temp)\n",
    "    utils.rasterize_reference_polygons(test_polygons, image, test_temp)\n",
    "\n",
    "    # train and test images matched to 10m image\n",
    "    train_image_matched = utils.match_rasters(train_temp, image)\n",
    "    test_image_matched = utils.match_rasters(test_temp, image)\n",
    "\n",
    "    # save\n",
    "    train_image_matched.rio.to_raster(train_polygons_raster, driver=\"GTiff\", compress=\"LZW\")\n",
    "    test_image_matched.rio.to_raster(test_polygons_raster, driver=\"GTiff\", compress=\"LZW\")\n",
    "\n",
    "    # cleaning\n",
    "    train_image_matched.close()\n",
    "    test_image_matched.close()\n",
    "    train_image_matched = None\n",
    "    test_image_matched = None\n",
    "    gc.collect()\n",
    "    if os.path.exists(train_temp):\n",
    "        os.remove(train_temp)\n",
    "    if os.path.exists(test_temp):\n",
    "        os.remove(test_temp)\n",
    "\n",
    "    ## load trained CNN model\n",
    "    cnn_model = MSMLA50(input_channels=10, depth=[16,32,48], num_classes=len(train_polygons[\"gridcode\"].unique()))\n",
    "    cnn_model = cnn_model.cuda()\n",
    "    trained_model = torch.load(cnn_models[fold])\n",
    "    cnn_model.load_state_dict(trained_model['model_state'])\n",
    "\n",
    "    ## get training patches\n",
    "    train_patches = cnn_utils.generate_labeled_patches_loader(image_path = image,reference_path = train_polygons_raster,patch_size = patch_size,stride = gt_stride,batch_size = batch_size,offset_left = offset_left,offset_top = offset_top,background_label = background_label)\n",
    "\n",
    "    ## remapping labels\n",
    "    label_mapping = cnn_utils.compute_label_mapping(train_patches)\n",
    "    train_patches = cnn_utils.label_remapping(train_patches, label_mapping)\n",
    "\n",
    "    ## normalize patches\n",
    "    mean, std = cnn_utils.get_normalization_parameters(train_patches)\n",
    "    feature_patches_norm = cnn_utils.normalize_loader(feature_patches, mean, std)\n",
    "\n",
    "    ## prediction\n",
    "    print(f\"Prediction started for fold {fold}...\")\n",
    "    cnn_model.eval()\n",
    "    all_preds = list()\n",
    "    with torch.no_grad():\n",
    "        for features in feature_patches_norm:\n",
    "            features = features.cuda()\n",
    "            \n",
    "            pred = cnn_model(features)\n",
    "            pred = pred.cpu()\n",
    "            \n",
    "            _, predicted = torch.max(pred, 1)\n",
    "            all_preds.append(predicted)\n",
    "    y_pred = torch.cat(all_preds, dim=0)\n",
    "\n",
    "    ## remapping labels back\n",
    "    inverse_mapping = {new_label: old_label for old_label, new_label in label_mapping.items()}\n",
    "    predicted_original_labels = np.array([inverse_mapping[label] for label in y_pred.numpy()])\n",
    "\n",
    "    ## generate lcz map\n",
    "    offset_left_calc, offset_top_calc = cnn_utils.calculate_optimal_offsets(image, patch_size, stride)\n",
    "    utils.lcz_map(offset_left_calc, offset_top_calc, image, predicted_original_labels, outputs[fold])\n",
    "\n",
    "    print(f\"Fold {fold} predicted and saved to {outputs[fold]}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613606fe-a29d-468a-a67b-8c2c29af8a41",
   "metadata": {},
   "source": [
    "## Perpixel validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0ea9725b-4e1d-491c-874f-8cbe7e4feb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide test polygons raster path\n",
    "test_polygons_path = ['saopaulo_test_f0.tif','saopaulo_test_f1.tif','saopaulo_test_f2.tif','saopaulo_test_f3.tif','saopaulo_test_f4.tif']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b013f6ef-23dc-4f20-a44f-895dffdfd573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " saved to s2_outputs\\saopaulo_S2_fold0_100m.tif\n",
      " saved to s2_outputs\\saopaulo_S2_fold1_100m.tif\n",
      " saved to s2_outputs\\saopaulo_S2_fold2_100m.tif\n",
      " saved to s2_outputs\\saopaulo_S2_fold3_100m.tif\n",
      " saved to s2_outputs\\saopaulo_S2_fold4_100m.tif\n"
     ]
    }
   ],
   "source": [
    "# resample lcz map to 100m\n",
    "resampled_outputs = []\n",
    "for f in outputs:\n",
    "    out = f.replace(\".tif\", \"_100m.tif\")\n",
    "    utils.resample_lcz_map(f, out)\n",
    "    resampled_outputs.append(out)\n",
    "    # if os.path.exists(f):\n",
    "    #     try:\n",
    "    #         os.remove(f)\n",
    "    #     except:\n",
    "    #         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8ddfd113-5588-4777-a56c-95a919d1f79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics, confusion_matrices = utils.perpixel_validation(resampled_outputs, test_polygons_path, splited_ref_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0f423327-f65c-48f8-8baa-f99d3a901477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OA</th>\n",
       "      <th>wF1</th>\n",
       "      <th>wF1_Urban</th>\n",
       "      <th>wF1_Natural</th>\n",
       "      <th>F1_Class_1</th>\n",
       "      <th>F1_Class_2</th>\n",
       "      <th>F1_Class_3</th>\n",
       "      <th>F1_Class_4</th>\n",
       "      <th>F1_Class_5</th>\n",
       "      <th>F1_Class_6</th>\n",
       "      <th>...</th>\n",
       "      <th>F1_Class_8</th>\n",
       "      <th>F1_Class_9</th>\n",
       "      <th>F1_Class_10</th>\n",
       "      <th>F1_Class_11</th>\n",
       "      <th>F1_Class_12</th>\n",
       "      <th>F1_Class_13</th>\n",
       "      <th>F1_Class_14</th>\n",
       "      <th>F1_Class_15</th>\n",
       "      <th>F1_Class_16</th>\n",
       "      <th>F1_Class_17</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83.86</td>\n",
       "      <td>82.90</td>\n",
       "      <td>80.15</td>\n",
       "      <td>91.41</td>\n",
       "      <td>92.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>94.70</td>\n",
       "      <td>55.88</td>\n",
       "      <td>17.44</td>\n",
       "      <td>75.32</td>\n",
       "      <td>...</td>\n",
       "      <td>85.21</td>\n",
       "      <td>68.95</td>\n",
       "      <td>0.00</td>\n",
       "      <td>88.18</td>\n",
       "      <td>43.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.72</td>\n",
       "      <td>99.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89.42</td>\n",
       "      <td>89.28</td>\n",
       "      <td>88.67</td>\n",
       "      <td>92.38</td>\n",
       "      <td>89.68</td>\n",
       "      <td>37.74</td>\n",
       "      <td>97.71</td>\n",
       "      <td>57.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>84.38</td>\n",
       "      <td>...</td>\n",
       "      <td>87.27</td>\n",
       "      <td>41.18</td>\n",
       "      <td>19.05</td>\n",
       "      <td>98.07</td>\n",
       "      <td>73.68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.00</td>\n",
       "      <td>99.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.22</td>\n",
       "      <td>88.31</td>\n",
       "      <td>82.17</td>\n",
       "      <td>92.62</td>\n",
       "      <td>85.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>92.57</td>\n",
       "      <td>57.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>80.95</td>\n",
       "      <td>...</td>\n",
       "      <td>90.45</td>\n",
       "      <td>62.28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.06</td>\n",
       "      <td>58.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.36</td>\n",
       "      <td>92.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>86.46</td>\n",
       "      <td>86.25</td>\n",
       "      <td>79.76</td>\n",
       "      <td>94.84</td>\n",
       "      <td>79.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>94.02</td>\n",
       "      <td>76.43</td>\n",
       "      <td>46.00</td>\n",
       "      <td>38.91</td>\n",
       "      <td>...</td>\n",
       "      <td>88.79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.19</td>\n",
       "      <td>68.24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.56</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90.87</td>\n",
       "      <td>90.95</td>\n",
       "      <td>89.31</td>\n",
       "      <td>93.20</td>\n",
       "      <td>87.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>96.36</td>\n",
       "      <td>65.96</td>\n",
       "      <td>8.51</td>\n",
       "      <td>90.06</td>\n",
       "      <td>...</td>\n",
       "      <td>85.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.00</td>\n",
       "      <td>99.18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         OA    wF1  wF1_Urban  wF1_Natural  F1_Class_1  F1_Class_2  \\\n",
       "Fold                                                                 \n",
       "0     83.86  82.90      80.15        91.41       92.24        0.00   \n",
       "1     89.42  89.28      88.67        92.38       89.68       37.74   \n",
       "2     88.22  88.31      82.17        92.62       85.64        0.00   \n",
       "3     86.46  86.25      79.76        94.84       79.08        0.00   \n",
       "4     90.87  90.95      89.31        93.20       87.07        0.00   \n",
       "\n",
       "      F1_Class_3  F1_Class_4  F1_Class_5  F1_Class_6  ...  F1_Class_8  \\\n",
       "Fold                                                  ...               \n",
       "0          94.70       55.88       17.44       75.32  ...       85.21   \n",
       "1          97.71       57.30        0.00       84.38  ...       87.27   \n",
       "2          92.57       57.73        0.00       80.95  ...       90.45   \n",
       "3          94.02       76.43       46.00       38.91  ...       88.79   \n",
       "4          96.36       65.96        8.51       90.06  ...       85.67   \n",
       "\n",
       "      F1_Class_9  F1_Class_10  F1_Class_11  F1_Class_12  F1_Class_13  \\\n",
       "Fold                                                                   \n",
       "0          68.95         0.00        88.18        43.30          NaN   \n",
       "1          41.18        19.05        98.07        73.68          NaN   \n",
       "2          62.28          NaN        95.06        58.12          NaN   \n",
       "3            NaN          NaN        98.19        68.24          NaN   \n",
       "4            NaN          NaN        98.51         0.00          NaN   \n",
       "\n",
       "      F1_Class_14  F1_Class_15  F1_Class_16  F1_Class_17  \n",
       "Fold                                                      \n",
       "0           41.03          0.0        19.72        99.94  \n",
       "1           55.64          0.0        15.00        99.65  \n",
       "2           53.73          0.0        20.36        92.97  \n",
       "3           87.62          0.0         5.56       100.00  \n",
       "4           30.57          0.0        50.00        99.18  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_perpixel = pd.DataFrame(metrics)\n",
    "df_perpixel = df_perpixel.set_index(\"Fold\")\n",
    "df_perpixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "69c30a13-9cb7-4098-adc2-fe74501766aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OA             87.77\n",
       "wF1            87.54\n",
       "wF1_Urban      84.01\n",
       "wF1_Natural    92.89\n",
       "F1_Class_1     86.74\n",
       "F1_Class_2      7.55\n",
       "F1_Class_3     95.07\n",
       "F1_Class_4     62.66\n",
       "F1_Class_5     14.39\n",
       "F1_Class_6     73.92\n",
       "F1_Class_7       NaN\n",
       "F1_Class_8     87.48\n",
       "F1_Class_9     57.47\n",
       "F1_Class_10     9.52\n",
       "F1_Class_11    95.60\n",
       "F1_Class_12    48.67\n",
       "F1_Class_13      NaN\n",
       "F1_Class_14    53.72\n",
       "F1_Class_15     0.00\n",
       "F1_Class_16    22.13\n",
       "F1_Class_17    98.35\n",
       "dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_perpixel_mean = df_perpixel.mean().round(2)\n",
    "df_perpixel_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f056c016-1265-45c1-887e-0f372df53a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export all results to csv\n",
    "df_perpixel.to_csv(r\"results\\s2\\saopaulo_S2_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1f129e26-34c3-4e54-9110-af6d0c425eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export confusion matrices\n",
    "with open(r\"results\\s2\\saopaulo_S2_confusion_matrices.pkl\", \"wb\") as f:\n",
    "    pickle.dump(confusion_matrices, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
