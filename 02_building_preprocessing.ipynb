{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0efb118-ccd4-4ae4-8f46-83bde848244d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geoplanar\n",
    "import geopandas as gpd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062d5988-917e-4d2a-b0af-0f518d624c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load downloaded buildings of a site\n",
    "buildings = gpd.read_file(r\"overture_data\\berlin_buildings.gpkg\")\n",
    "#buildings = gpd.read_file(r\"overture_data\\hongkong_buildings.gpkg\")\n",
    "#buildings = gpd.read_file(r\"overture_data\\paris_buildings.gpkg\")\n",
    "#buildings = gpd.read_file(r\"overture_data\\rome_buildings.gpkg\")\n",
    "#buildings = gpd.read_file(r\"overture_data\\saopaulo_buildings.gpkg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c662bd-2a60-415c-994f-40c96dfcd50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_region_buildings(buildings, simplify, simplification_tolerance=.1, merge_limit=25):\n",
    "    '''Pass the region buildings through the geoplanar simplification pipeline.'''\n",
    "    \n",
    "    initial_shape = buildings.shape\n",
    "\n",
    "    ## fix invalid geometry\n",
    "    buildings[\"geometry\"] = buildings.make_valid()\n",
    "\n",
    "    ## explode multipolygons\n",
    "    buildings = buildings.explode(ignore_index=True)\n",
    "\n",
    "    ## keep only polygons\n",
    "    buildings = buildings[buildings[\"geometry\"].geom_type == \"Polygon\"].reset_index(\n",
    "        drop=True\n",
    "    )\n",
    "\n",
    "    ## simplify geometry - most eubucco data has topological issues\n",
    "    ## one region - 109491 - has an issue with simplification, without normalisation\n",
    "    if simplify:\n",
    "        buildings[\"geometry\"] = buildings.simplify(simplification_tolerance).normalize()\n",
    "\n",
    "    # drop very large buildings\n",
    "    buildings = buildings[buildings.area < 200_000].reset_index(drop=True)\n",
    "\n",
    "    \n",
    "    ## merge buildings that overlap either 1) at least .10 percent or are smaller than 30m^2\n",
    "    buildings = geoplanar.merge_overlaps(\n",
    "        buildings, merge_limit=merge_limit, overlap_limit=0.1\n",
    "    )\n",
    "\n",
    "    ## drop remaining overlaps\n",
    "    buildings = geoplanar.trim_overlaps(buildings, strategy='largest')\n",
    "\n",
    "    ## fix any multipolygons\n",
    "    buildings = buildings.explode(ignore_index=True)\n",
    "\n",
    "    print(\n",
    "        \"Percent polygons: \",\n",
    "        (buildings.geom_type == \"Polygon\").sum() / buildings.shape[0],\n",
    "    )\n",
    "\n",
    "    # drop non-polygons\n",
    "    buildings = buildings[buildings.geom_type == \"Polygon\"].reset_index(drop=True)\n",
    "\n",
    "    # merge touching collapsing buildings\n",
    "    shrink = buildings.buffer(-0.5, resolution=2)\n",
    "    buildings = geoplanar.merge_touching(\n",
    "        buildings, np.where(shrink.is_empty), largest=True\n",
    "    )\n",
    "    # drop non polygons\n",
    "    buildings = buildings.explode(ignore_index=True)\n",
    "    buildings = buildings[buildings.geom_type == \"Polygon\"].reset_index(drop=True)\n",
    "\n",
    "    ## need one more pass to ensure only valid geometries\n",
    "    if simplify:\n",
    "        buildings[\"geometry\"] = buildings.simplify(simplification_tolerance)\n",
    "        buildings[\"geometry\"] = buildings.make_valid()\n",
    "        buildings = buildings[buildings.geom_type == \"Polygon\"].reset_index(drop=True)\n",
    "\n",
    "    print(\n",
    "        \"Final polygons: \",\n",
    "        buildings.shape[0],\n",
    "        \", dropped: \",\n",
    "        1 - (buildings.shape[0] / initial_shape[0]),\n",
    "    )\n",
    "\n",
    "    buildings[\"geometry\"] = buildings.normalize()\n",
    "    return buildings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15131b5d-7985-436f-ad54-7ac3f399b6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_buildings = process_region_buildings(buildings=buildings, simplify=True, simplification_tolerance=.1, merge_limit=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e94d82-1d93-4e73-badb-185cd8a401c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save preprocessed buildings\n",
    "processed_buildings.to_file(r\"overture_data\\berlin_buildings_preprocessed.gpkg\", driver=\"GPKG\")\n",
    "#processed_buildings.to_file(r\"overture_data\\hongkong_buildings_preprocessed.gpkg\", driver=\"GPKG\")\n",
    "#processed_buildings.to_file(r\"overture_data\\paris_buildings_preprocessed.gpkg\", driver=\"GPKG\")\n",
    "#processed_buildings.to_file(r\"overture_data\\rome_buildings_preprocessed.gpkg\", driver=\"GPKG\")\n",
    "#processed_buildings.to_file(r\"overture_data\\saopaulo_buildings_preprocessed.gpkg\", driver=\"GPKG\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
